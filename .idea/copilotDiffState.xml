<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/batch_processor.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/batch_processor.py" />
              <option name="originalContent" value="#!/usr/bin/env python3&#10;&quot;&quot;&quot;&#10;Unified Batch Processor for Vast.ai&#10;&#10;This script replaces:&#10;- run_with_config_batch_sync.py&#10;- run_with_config_batch.py&#10;- run_with_config.py&#10;- run_slim_vast.py&#10;&#10;Usage:&#10;    # Process single file&#10;    python batch_processor.py --input video.mp4&#10;&#10;    # Process directory from B2&#10;    python batch_processor.py --input-dir input/batch1&#10;&#10;    # Process with config&#10;    python batch_processor.py --config config.yaml --input-dir input/batch1&#10;&#10;    # Dry run (show what would be processed)&#10;    python batch_processor.py --input-dir input/batch1 --dry-run&#10;&quot;&quot;&quot;&#10;&#10;import os&#10;import sys&#10;import argparse&#10;import yaml&#10;import logging&#10;from pathlib import Path&#10;from typing import List, Optional, Dict, Any&#10;from datetime import datetime&#10;&#10;# Load .env file if present&#10;try:&#10;    from dotenv import load_dotenv&#10;    load_dotenv()&#10;except ImportError:&#10;    pass  # dotenv not installed, will use system env vars&#10;&#10;# Add src to path&#10;_SRC_DIR = Path(__file__).parent / 'src'&#10;if str(_SRC_DIR) not in sys.path:&#10;    sys.path.insert(0, str(_SRC_DIR))&#10;&#10;try:&#10;    from domain.b2_storage import B2Credentials, B2Object&#10;    from domain.vastai import VastInstanceConfig&#10;    from infrastructure.storage.b2_client import B2Client&#10;    from infrastructure.vastai.client import VastAIClient&#10;    from shared.logging import get_logger&#10;    from shared.remote_config import load_config_with_remote&#10;&#10;    # Get logger&#10;    logger = get_logger(__name__)&#10;except ImportError as e:&#10;    import logging&#10;    logger = logging.getLogger(__name__)&#10;    logging.basicConfig(level=logging.INFO)&#10;    logger.error(f&quot;Failed to import modules: {e}&quot;)&#10;    logger.error(&quot;Make sure you're running from project root&quot;)&#10;    sys.exit(1)&#10;&#10;&#10;class BatchProcessor:&#10;    &quot;&quot;&quot;&#10;    Unified batch processor for Vast.ai video processing.&#10;&#10;    Handles:&#10;    - Single file processing&#10;    - Batch directory processing&#10;    - Vast.ai instance management&#10;    - B2 storage integration&#10;    &quot;&quot;&quot;&#10;&#10;    def __init__(self, config_path: str = 'config.yaml'):&#10;        &quot;&quot;&quot;&#10;        Initialize batch processor.&#10;&#10;        Args:&#10;            config_path: Path to config file&#10;        &quot;&quot;&quot;&#10;        self.config_path = config_path&#10;        self.config = self._load_config()&#10;&#10;&#10;        # Initialize clients&#10;        self.b2_client = None&#10;        self.vast_client = None&#10;&#10;        self._init_clients()&#10;&#10;    def _load_config(self) -&gt; Dict[str, Any]:&#10;        &quot;&quot;&quot;Load configuration from YAML file and merge with remote config if config_url is set.&quot;&quot;&quot;&#10;        return load_config_with_remote(Path(self.config_path), logger_instance=logger)&#10;&#10;    def _init_clients(self):&#10;        &quot;&quot;&quot;Initialize B2 and Vast.ai clients.&quot;&quot;&quot;&#10;        try:&#10;            # B2 client&#10;            b2_creds = B2Credentials.from_env()&#10;            if b2_creds.validate():&#10;                self.b2_client = B2Client(b2_creds)&#10;                logger.info(&quot;[OK] B2 client initialized&quot;)&#10;            else:&#10;                logger.warning(&quot;[WARN] B2 credentials not set (B2_KEY, B2_SECRET, B2_BUCKET)&quot;)&#10;&#10;        except Exception as e:&#10;            logger.error(f&quot;Failed to initialize B2 client: {e}&quot;)&#10;&#10;        try:&#10;            # Vast.ai client&#10;            self.vast_client = VastAIClient()&#10;            logger.info(&quot;[OK] Vast.ai client initialized&quot;)&#10;        except Exception as e:&#10;            logger.error(f&quot;Failed to initialize Vast.ai client: {e}&quot;)&#10;&#10;    def list_input_files(&#10;        self,&#10;        input_dir: str,&#10;        skip_existing: bool = True&#10;    ) -&gt; List['B2Object']:&#10;        &quot;&quot;&quot;&#10;        List video files from B2 input directory.&#10;&#10;        Args:&#10;            input_dir: Input directory in B2&#10;            skip_existing: Skip files that already have output&#10;&#10;        Returns:&#10;            List of B2Object instances&#10;        &quot;&quot;&quot;&#10;        if not self.b2_client:&#10;            raise RuntimeError(&quot;B2 client not initialized&quot;)&#10;&#10;        # Build prefix&#10;        prefix = input_dir if input_dir.startswith('input/') else f'input/{input_dir}'&#10;&#10;        logger.info(f&quot;[LIST] Listing files from B2: {prefix}&quot;)&#10;&#10;        # List objects&#10;        objects = self.b2_client.list_objects(prefix=prefix)&#10;&#10;        # Filter video files&#10;        video_extensions = ('.mp4', '.mkv', '.mov', '.avi', '.webm')&#10;        video_files = [&#10;            obj for obj in objects&#10;            if obj.key.lower().endswith(video_extensions) and obj.size &gt; 0&#10;        ]&#10;&#10;        logger.info(f&quot;[OK] Found {len(video_files)} video files&quot;)&#10;&#10;        # Skip existing outputs if requested&#10;        if skip_existing:&#10;            video_files = self._filter_existing_outputs(video_files)&#10;&#10;        return video_files&#10;&#10;    def _monitor_processing(self, instance_id: int, timeout: int = 7200) -&gt; Optional[str]:&#10;        &quot;&quot;&quot;&#10;        Monitor instance processing and extract result URL.&#10;&#10;        Args:&#10;            instance_id: Instance ID to monitor&#10;            timeout: Maximum time to wait in seconds&#10;&#10;        Returns:&#10;            Result URL if found, None otherwise&#10;        &quot;&quot;&quot;&#10;        import time&#10;        import re&#10;&#10;        start_time = time.time()&#10;        last_log_line = 0&#10;        success_marker = &quot;VASTAI_PIPELINE_COMPLETED_SUCCESSFULLY&quot;&#10;        url_pattern = r'https://[^\s]+'&#10;&#10;        logger.info(f&quot;[MONITOR] Watching logs for instance #{instance_id}...&quot;)&#10;&#10;        consecutive_failures = 0&#10;        max_consecutive_failures = 6  # 6 failures = 1 minute of no response&#10;        check_count = 0&#10;        lines = []  # Initialize to avoid undefined variable&#10;&#10;        while time.time() - start_time &lt; timeout:&#10;            try:&#10;                check_count += 1&#10;                elapsed = int(time.time() - start_time)&#10;&#10;                # Progress indicator every 30 seconds&#10;                if check_count % 6 == 0:&#10;                    logger.info(f&quot;[MONITOR] Still monitoring... ({elapsed}s elapsed, {len(lines)} log lines)&quot;)&#10;&#10;                # Get logs&#10;                logs = self.vast_client.get_instance_logs(instance_id, tail=500)&#10;&#10;                if not logs:&#10;                    consecutive_failures += 1&#10;                    if consecutive_failures == 1:&#10;                        logger.info(f&quot;[MONITOR] Waiting for logs to appear...&quot;)&#10;                    elif consecutive_failures &gt;= max_consecutive_failures:&#10;                        logger.warning(f&quot;[WARN] No logs after {consecutive_failures * 10}s, but continuing...&quot;)&#10;                        consecutive_failures = 0  # Reset to avoid spam&#10;                    time.sleep(10)&#10;                    continue&#10;&#10;                # Reset failure counter on success&#10;                consecutive_failures = 0&#10;&#10;                lines = logs.split('\n')&#10;&#10;                # Show new lines (only if there are actually new lines)&#10;                if len(lines) &gt; last_log_line:&#10;                    new_lines = lines[last_log_line:]&#10;                    new_content = [line for line in new_lines if line.strip()]&#10;&#10;                    if new_content:&#10;                        for line in new_content:&#10;                            logger.info(f&quot;  [LOG] {line}&quot;)&#10;                        last_log_line = len(lines)&#10;&#10;                # Check for success&#10;                if success_marker in logs:&#10;                    logger.info(f&quot;[OK] Processing completed successfully!&quot;)&#10;&#10;                    # Extract result URL&#10;                    urls = re.findall(url_pattern, logs)&#10;                    for url in reversed(urls):  # Get last URL&#10;                        if 'noxfvr-videos' in url and ('output/' in url or 'both/' in url or 'upscales/' in url or 'interps/' in url):&#10;                            logger.info(f&quot;[RESULT] Download URL: {url}&quot;)&#10;                            return url&#10;&#10;                    logger.warning(&quot;[WARN] Success marker found but no result URL&quot;)&#10;                    return None&#10;&#10;                # Check for pipeline failure (immediate termination)&#10;                pipeline_failed_marker = &quot;ERROR: Pipeline failed with exit code&quot;&#10;                if pipeline_failed_marker in logs:&#10;                    logger.error(f&quot;[ERROR] Pipeline failed - stopping monitoring&quot;)&#10;                    # Extract last error&#10;                    error_lines = [l for l in lines if 'ERROR' in l]&#10;                    if error_lines:&#10;                        logger.error(f&quot;[ERROR] Last error: {error_lines[-1][:200]}&quot;)&#10;                    return None  # Exit monitoring, instance will be destroyed&#10;&#10;                # Check for other errors (only report periodically)&#10;                if check_count == 1 or (check_count % 12 == 0):  # Check every 2 minutes&#10;                    if 'ERROR' in logs or 'FAILED' in logs:&#10;                        error_lines = [l for l in lines if 'ERROR' in l or 'FAILED' in l]&#10;                        if error_lines:&#10;                            logger.warning(f&quot;[WARN] Recent errors: {error_lines[-1][:100]}&quot;)&#10;&#10;                time.sleep(10)&#10;&#10;            except Exception as e:&#10;                consecutive_failures += 1&#10;                if consecutive_failures &lt;= 3:  # Only log first 3 failures&#10;                    logger.warning(f&quot;[WARN] Log fetch failed (attempt {consecutive_failures}): {e}&quot;)&#10;                time.sleep(10)&#10;&#10;        logger.error(f&quot;[ERROR] Monitoring timeout after {timeout}s&quot;)&#10;        return None&#10;&#10;    def _filter_existing_outputs(self, files: List) -&gt; List:&#10;        &quot;&quot;&quot;Filter out files that already have output.&quot;&quot;&quot;&#10;        if not self.b2_client:&#10;            return files&#10;&#10;        try:&#10;            # List existing outputs&#10;            output_objects = self.b2_client.list_objects(prefix='output/')&#10;            existing_stems = {obj.stem for obj in output_objects}&#10;&#10;            # Filter&#10;            filtered = []&#10;            skipped = 0&#10;&#10;            for file_obj in files:&#10;                stem = file_obj.stem&#10;                if stem in existing_stems:&#10;                    logger.info(f&quot;[WARN] Skipping {file_obj.key} - output exists&quot;)&#10;                    skipped += 1&#10;                else:&#10;                    filtered.append(file_obj)&#10;&#10;            if skipped &gt; 0:&#10;                logger.info(f&quot;Skipped {skipped} files with existing outputs&quot;)&#10;&#10;            return filtered&#10;&#10;        except Exception as e:&#10;            logger.warning(f&quot;Could not check existing outputs: {e}&quot;)&#10;            return files&#10;&#10;    def process_single_file(&#10;        self,&#10;        input_url: str,&#10;        output_name: Optional[str] = None,&#10;        preset: str = 'balanced'&#10;    ) -&gt; Dict[str, Any]:&#10;        &quot;&quot;&quot;&#10;        Process single file on Vast.ai.&#10;&#10;        Args:&#10;            input_url: Input file URL&#10;            output_name: Output file name (auto-generated if None)&#10;            preset: Preset name from config&#10;&#10;        Returns:&#10;            Processing result dict&#10;        &quot;&quot;&quot;&#10;        if not self.vast_client:&#10;            raise RuntimeError(&quot;Vast.ai client not initialized&quot;)&#10;&#10;        # Generate output name if not provided&#10;        if not output_name:&#10;            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')&#10;            output_name = f&quot;output_{timestamp}.mp4&quot;&#10;&#10;        logger.info(f&quot;[RUN] Processing file: {input_url}&quot;)&#10;        logger.info(f&quot;   Output: {output_name}&quot;)&#10;        logger.info(f&quot;   Preset: {preset}&quot;)&#10;&#10;        # Get preset config&#10;        preset_config = self.config.get('presets', {}).get(preset, {})&#10;        if not preset_config:&#10;            raise ValueError(f&quot;Preset not found: {preset}&quot;)&#10;&#10;        # Search for offers&#10;        offers = self.vast_client.search_offers(&#10;            min_vram_gb=preset_config.get('min_vram', 12),&#10;            max_price=preset_config.get('max_price', 0.5),&#10;            min_reliability=preset_config.get('min_reliability', 0.9),&#10;            limit=10,&#10;            host_whitelist=preset_config.get('host_whitelist'),&#10;            host_blacklist=preset_config.get('host_blacklist')&#10;        )&#10;&#10;        if not offers:&#10;            raise RuntimeError(&quot;No suitable offers found&quot;)&#10;&#10;        # Use best offer (first one - already sorted by price)&#10;        offer = offers[0]&#10;        logger.info(f&quot;[OK] Selected offer: {offer}&quot;)&#10;&#10;        # Build instance config&#10;        video_config = self.config.get('video', {})&#10;&#10;        # Get git repo URL and branch from config&#10;        git_repo = self.config.get('git_repo', 'https://github.com/zerotouchprod/vastai_inerup.git')&#10;        git_branch = self.config.get('git_branch', 'oop2')&#10;&#10;        instance_config = VastInstanceConfig(&#10;            image=self.config.get('image', ''),&#10;            disk=50,&#10;            env={&#10;                'INPUT_URL': input_url,&#10;                'B2_OUTPUT_KEY': f&quot;output/{output_name}&quot;,&#10;                'B2_BUCKET': os.getenv('B2_BUCKET', ''),&#10;                'B2_KEY': os.getenv('B2_KEY', ''),&#10;                'B2_SECRET': os.getenv('B2_SECRET', ''),&#10;                'B2_ENDPOINT': os.getenv('B2_ENDPOINT', 'https://s3.us-west-004.backblazeb2.com'),&#10;                'MODE': video_config.get('mode', 'both'),&#10;                'SCALE': str(video_config.get('scale', 2)),&#10;                'TARGET_FPS': str(video_config.get('target_fps', 60)),&#10;                'USE_NATIVE_PROCESSORS': '1',  # Use new Python code!&#10;                # Pass Git info to entrypoint via env vars&#10;                'GIT_REPO': git_repo,&#10;                'GIT_BRANCH': git_branch,&#10;            },&#10;            # No onstart - let entrypoint handle everything&#10;            # No label - reuse cached image on same host&#10;        )&#10;&#10;        # Create instance&#10;        instance = self.vast_client.create_instance(offer.id, instance_config)&#10;        logger.info(f&quot;[OK] Created instance: {instance}&quot;)&#10;&#10;        # Wait for running&#10;        try:&#10;            instance = self.vast_client.wait_for_running(&#10;                instance.id,&#10;                timeout=300,&#10;                poll_interval=10&#10;            )&#10;            logger.info(f&quot;[OK] Instance running: {instance}&quot;)&#10;        except TimeoutError as e:&#10;            logger.error(f&quot;Instance failed to start: {e}&quot;)&#10;            raise&#10;&#10;        # Monitor processing&#10;        logger.info(f&quot;[MONITOR] Monitoring instance #{instance.id} for completion...&quot;)&#10;        result_url = self._monitor_processing(instance.id, timeout=7200)  # 2 hours max&#10;&#10;        # Stop instance (keep for debugging instead of destroying)&#10;        logger.info(f&quot;[CLEANUP] Stopping instance #{instance.id}...&quot;)&#10;        self.vast_client.stop_instance(instance.id)&#10;        logger.info(f&quot;[OK] Instance stopped (kept for debugging)&quot;)&#10;&#10;        return {&#10;            'instance_id': instance.id,&#10;            'input_url': input_url,&#10;            'output_name': output_name,&#10;            'result_url': result_url,&#10;            'status': 'completed' if result_url else 'failed'&#10;        }&#10;&#10;    def process_batch(&#10;        self,&#10;        input_dir: str,&#10;        preset: str = 'balanced',&#10;        dry_run: bool = False&#10;    ) -&gt; List[Dict[str, Any]]:&#10;        &quot;&quot;&quot;&#10;        Process batch of files from B2 directory.&#10;&#10;        Args:&#10;            input_dir: Input directory in B2&#10;            preset: Preset name from config&#10;            dry_run: If True, only show what would be processed&#10;&#10;        Returns:&#10;            List of processing results&#10;        &quot;&quot;&quot;&#10;        # List files&#10;        files = self.list_input_files(input_dir)&#10;&#10;        if not files:&#10;            logger.info(&quot;No files to process&quot;)&#10;            return []&#10;&#10;        logger.info(f&quot;[STAT] {len(files)} files to process&quot;)&#10;&#10;        if dry_run:&#10;            logger.info(&quot;[DRY] Dry run - not creating instances&quot;)&#10;            for idx, file_obj in enumerate(files, 1):&#10;                logger.info(f&quot;  {idx}. {file_obj.key} ({file_obj.size} bytes)&quot;)&#10;            return []&#10;&#10;        # Process each file&#10;        results = []&#10;&#10;        for idx, file_obj in enumerate(files, 1):&#10;            logger.info(f&quot;\n{'='*60}&quot;)&#10;            logger.info(f&quot;Processing file {idx}/{len(files)}&quot;)&#10;            logger.info(f&quot;{'='*60}\n&quot;)&#10;&#10;            try:&#10;                # Get presigned URL&#10;                input_url = self.b2_client.get_presigned_url(&#10;                    file_obj.key,&#10;                    expires_in=7200  # 2 hours&#10;                )&#10;&#10;                # Generate output name&#10;                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')&#10;                output_name = f&quot;{file_obj.stem}_{timestamp}.mp4&quot;&#10;&#10;                # Process&#10;                result = self.process_single_file(&#10;                    input_url=input_url,&#10;                    output_name=output_name,&#10;                    preset=preset&#10;                )&#10;&#10;                results.append(result)&#10;                logger.info(f&quot;[OK] File {idx}/{len(files)} submitted&quot;)&#10;&#10;            except Exception as e:&#10;                logger.error(f&quot;[ERROR] Failed to process {file_obj.key}: {e}&quot;)&#10;                import traceback&#10;                traceback.print_exc()&#10;                continue&#10;&#10;        return results&#10;&#10;&#10;def main():&#10;    &quot;&quot;&quot;Main entry point.&quot;&quot;&quot;&#10;    parser = argparse.ArgumentParser(&#10;        description='Unified Batch Processor for Vast.ai - reads defaults from config.yaml'&#10;    )&#10;&#10;    parser.add_argument('--config', default='config.yaml',&#10;                       help='Config file (default: config.yaml)')&#10;    parser.add_argument('--input', help='Single input file URL (overrides config)')&#10;    parser.add_argument('--input-dir', help='Input directory in B2 (overrides config)')&#10;    parser.add_argument('--output', help='Output file name (for single file)')&#10;    parser.add_argument('--preset', help='Preset name (overrides config)')&#10;    parser.add_argument('--dry-run', action='store_true', default=None,&#10;                       help='Show what would be processed (overrides config)')&#10;    parser.add_argument('--skip-existing', action='store_true', default=None,&#10;                       help='Skip files with existing output (overrides config)')&#10;&#10;    args = parser.parse_args()&#10;&#10;    try:&#10;        # Initialize processor&#10;        processor = BatchProcessor(config_path=args.config)&#10;&#10;        # Get batch config from config.yaml&#10;        batch_config = processor.config.get('batch', {})&#10;        video_config = processor.config.get('video', {})&#10;&#10;        # Determine input source (CLI args override config)&#10;        input_url = args.input&#10;        # Priority: CLI &gt; video.input_dir (remote) &gt; batch.input_dir (local)&#10;        # Remote config should override local config&#10;        input_dir = args.input_dir or video_config.get('input_dir') or batch_config.get('input_dir')&#10;        preset = args.preset or batch_config.get('preset', 'balanced')&#10;        dry_run = args.dry_run if args.dry_run is not None else batch_config.get('dry_run', False)&#10;        skip_existing = args.skip_existing if args.skip_existing is not None else batch_config.get('skip_existing', True)&#10;&#10;        # Validate: need either input or input_dir&#10;        if not input_url and not input_dir:&#10;            logger.error(&quot;[ERROR] No input specified!&quot;)&#10;            logger.error(&quot;Either:&quot;)&#10;            logger.error(&quot;  1. Set 'batch.input_dir' in config.yaml&quot;)&#10;            logger.error(&quot;  2. Use --input &lt;url&gt; for single file&quot;)&#10;            logger.error(&quot;  3. Use --input-dir &lt;dir&gt; for batch&quot;)&#10;            sys.exit(1)&#10;&#10;        # Validate credentials before processing&#10;        if input_dir and not processor.b2_client:&#10;            logger.error(&quot;[ERROR] B2 client not initialized - cannot list files from B2&quot;)&#10;            logger.error(&quot;Please set environment variables:&quot;)&#10;            logger.error(&quot;  $env:B2_KEY='your_key_id'&quot;)&#10;            logger.error(&quot;  $env:B2_SECRET='your_application_key'&quot;)&#10;            logger.error(&quot;  $env:B2_BUCKET='noxfvr-videos'&quot;)&#10;            sys.exit(1)&#10;&#10;        if not processor.vast_client:&#10;            logger.error(&quot;[ERROR] Vast.ai client not initialized - cannot create instances&quot;)&#10;            logger.error(&quot;Please set environment variable:&quot;)&#10;            logger.error(&quot;  $env:VAST_API_KEY='your_vast_api_key'&quot;)&#10;            sys.exit(1)&#10;&#10;        # Process&#10;        if input_url:&#10;            # Single file&#10;            logger.info(f&quot;[FILE] Processing single file: {input_url}&quot;)&#10;            result = processor.process_single_file(&#10;                input_url=input_url,&#10;                output_name=args.output,&#10;                preset=preset&#10;            )&#10;            logger.info(f&quot;\n[OK] Processing submitted: {result}&quot;)&#10;&#10;        elif input_dir:&#10;            # Batch&#10;            logger.info(f&quot;[DIR] Processing batch from: {input_dir}&quot;)&#10;            logger.info(f&quot;[CFG] Preset: {preset}&quot;)&#10;            logger.info(f&quot;[DRY] Dry run: {dry_run}&quot;)&#10;            logger.info(f&quot;[SKIP] Skip existing: {skip_existing}\n&quot;)&#10;&#10;            results = processor.process_batch(&#10;                input_dir=input_dir,&#10;                preset=preset,&#10;                dry_run=dry_run&#10;            )&#10;            logger.info(f&quot;\n[OK] Batch processing complete: {len(results)} files submitted&quot;)&#10;&#10;    except Exception as e:&#10;        logger.error(f&quot;\n[ERROR] Error: {e}&quot;)&#10;        import traceback&#10;        traceback.print_exc()&#10;        sys.exit(1)&#10;&#10;&#10;if __name__ == '__main__':&#10;    main()&#10;&#10;" />
              <option name="updatedContent" value="#!/usr/bin/env python3&#10;&quot;&quot;&quot;&#10;Unified Batch Processor for Vast.ai&#10;&#10;This script replaces:&#10;- run_with_config_batch_sync.py&#10;- run_with_config_batch.py&#10;- run_with_config.py&#10;- run_slim_vast.py&#10;&#10;Usage:&#10;    # Process single file&#10;    python batch_processor.py --input video.mp4&#10;&#10;    # Process directory from B2&#10;    python batch_processor.py --input-dir input/batch1&#10;&#10;    # Process with config&#10;    python batch_processor.py --config config.yaml --input-dir input/batch1&#10;&#10;    # Dry run (show what would be processed)&#10;    python batch_processor.py --input-dir input/batch1 --dry-run&#10;&quot;&quot;&quot;&#10;&#10;import os&#10;import sys&#10;import argparse&#10;import yaml&#10;import logging&#10;from pathlib import Path&#10;from typing import List, Optional, Dict, Any&#10;from datetime import datetime&#10;&#10;# Load .env file if present&#10;try:&#10;    from dotenv import load_dotenv&#10;    load_dotenv()&#10;except ImportError:&#10;    pass  # dotenv not installed, will use system env vars&#10;&#10;# Add src to path&#10;_SRC_DIR = Path(__file__).parent / 'src'&#10;if str(_SRC_DIR) not in sys.path:&#10;    sys.path.insert(0, str(_SRC_DIR))&#10;&#10;try:&#10;    from domain.b2_storage import B2Credentials, B2Object&#10;    from domain.vastai import VastInstanceConfig&#10;    from infrastructure.storage.b2_client import B2Client&#10;    from infrastructure.vastai.client import VastAIClient&#10;    from shared.logging import get_logger&#10;    from shared.remote_config import load_config_with_remote&#10;&#10;    # Get logger&#10;    logger = get_logger(__name__)&#10;except ImportError as e:&#10;    import logging&#10;    logger = logging.getLogger(__name__)&#10;    logging.basicConfig(level=logging.INFO)&#10;    logger.error(f&quot;Failed to import modules: {e}&quot;)&#10;    logger.error(&quot;Make sure you're running from project root&quot;)&#10;    sys.exit(1)&#10;&#10;&#10;class BatchProcessor:&#10;    &quot;&quot;&quot;&#10;    Unified batch processor for Vast.ai video processing.&#10;&#10;    Handles:&#10;    - Single file processing&#10;    - Batch directory processing&#10;    - Vast.ai instance management&#10;    - B2 storage integration&#10;    &quot;&quot;&quot;&#10;&#10;    def __init__(self, config_path: str = 'config.yaml'):&#10;        &quot;&quot;&quot;&#10;        Initialize batch processor.&#10;&#10;        Args:&#10;            config_path: Path to config file&#10;        &quot;&quot;&quot;&#10;        self.config_path = config_path&#10;        self.config = self._load_config()&#10;&#10;&#10;        # Initialize clients&#10;        self.b2_client = None&#10;        self.vast_client = None&#10;&#10;        self._init_clients()&#10;&#10;    def _load_config(self) -&gt; Dict[str, Any]:&#10;        &quot;&quot;&quot;Load configuration from YAML file and merge with remote config if config_url is set.&quot;&quot;&quot;&#10;        return load_config_with_remote(Path(self.config_path), logger_instance=logger)&#10;&#10;    def _init_clients(self):&#10;        &quot;&quot;&quot;Initialize B2 and Vast.ai clients.&quot;&quot;&quot;&#10;        try:&#10;            # B2 client&#10;            b2_creds = B2Credentials.from_env()&#10;            if b2_creds.validate():&#10;                self.b2_client = B2Client(b2_creds)&#10;                logger.info(&quot;[OK] B2 client initialized&quot;)&#10;            else:&#10;                logger.warning(&quot;[WARN] B2 credentials not set (B2_KEY, B2_SECRET, B2_BUCKET)&quot;)&#10;&#10;        except Exception as e:&#10;            logger.error(f&quot;Failed to initialize B2 client: {e}&quot;)&#10;&#10;        try:&#10;            # Vast.ai client&#10;            self.vast_client = VastAIClient()&#10;            logger.info(&quot;[OK] Vast.ai client initialized&quot;)&#10;        except Exception as e:&#10;            logger.error(f&quot;Failed to initialize Vast.ai client: {e}&quot;)&#10;&#10;    def list_input_files(&#10;        self,&#10;        input_dir: str,&#10;        skip_existing: bool = True&#10;    ) -&gt; List['B2Object']:&#10;        &quot;&quot;&quot;&#10;        List video files from B2 input directory.&#10;&#10;        Args:&#10;            input_dir: Input directory in B2&#10;            skip_existing: Skip files that already have output&#10;&#10;        Returns:&#10;            List of B2Object instances&#10;        &quot;&quot;&quot;&#10;        if not self.b2_client:&#10;            raise RuntimeError(&quot;B2 client not initialized&quot;)&#10;&#10;        # Build prefix&#10;        prefix = input_dir if input_dir.startswith('input/') else f'input/{input_dir}'&#10;&#10;        logger.info(f&quot;[LIST] Listing files from B2: {prefix}&quot;)&#10;&#10;        # List objects&#10;        objects = self.b2_client.list_objects(prefix=prefix)&#10;&#10;        # Filter video files&#10;        video_extensions = ('.mp4', '.mkv', '.mov', '.avi', '.webm')&#10;        video_files = [&#10;            obj for obj in objects&#10;            if obj.key.lower().endswith(video_extensions) and obj.size &gt; 0&#10;        ]&#10;&#10;        logger.info(f&quot;[OK] Found {len(video_files)} video files&quot;)&#10;&#10;        # Skip existing outputs if requested&#10;        if skip_existing:&#10;            video_files = self._filter_existing_outputs(video_files)&#10;&#10;        return video_files&#10;&#10;    def _monitor_processing(self, instance_id: int, timeout: int = 7200) -&gt; Optional[str]:&#10;        &quot;&quot;&quot;&#10;        Monitor instance processing and extract result URL.&#10;&#10;        Args:&#10;            instance_id: Instance ID to monitor&#10;            timeout: Maximum time to wait in seconds&#10;&#10;        Returns:&#10;            Result URL if found, None otherwise&#10;        &quot;&quot;&quot;&#10;        import time&#10;        import re&#10;&#10;        start_time = time.time()&#10;        last_log_line = 0&#10;        success_marker = &quot;VASTAI_PIPELINE_COMPLETED_SUCCESSFULLY&quot;&#10;        url_pattern = r'https://[^\s]+'&#10;&#10;        logger.info(f&quot;[MONITOR] Watching logs for instance #{instance_id}...&quot;)&#10;&#10;        consecutive_failures = 0&#10;        max_consecutive_failures = 6  # 6 failures = 1 minute of no response&#10;        check_count = 0&#10;        lines = []  # Initialize to avoid undefined variable&#10;&#10;        while time.time() - start_time &lt; timeout:&#10;            try:&#10;                check_count += 1&#10;                elapsed = int(time.time() - start_time)&#10;&#10;                # Progress indicator every 30 seconds&#10;                if check_count % 6 == 0:&#10;                    logger.info(f&quot;[MONITOR] Still monitoring... ({elapsed}s elapsed, {len(lines)} log lines)&quot;)&#10;&#10;                # Get logs&#10;                logs = self.vast_client.get_instance_logs(instance_id, tail=500)&#10;&#10;                if not logs:&#10;                    consecutive_failures += 1&#10;                    if consecutive_failures == 1:&#10;                        logger.info(f&quot;[MONITOR] Waiting for logs to appear...&quot;)&#10;                    elif consecutive_failures &gt;= max_consecutive_failures:&#10;                        logger.warning(f&quot;[WARN] No logs after {consecutive_failures * 10}s, but continuing...&quot;)&#10;                        consecutive_failures = 0  # Reset to avoid spam&#10;                    time.sleep(10)&#10;                    continue&#10;&#10;                # Reset failure counter on success&#10;                consecutive_failures = 0&#10;&#10;                lines = logs.split('\n')&#10;&#10;                # Show new lines (only if there are actually new lines)&#10;                if len(lines) &gt; last_log_line:&#10;                    new_lines = lines[last_log_line:]&#10;                    new_content = [line for line in new_lines if line.strip()]&#10;&#10;                    if new_content:&#10;                        for line in new_content:&#10;                            logger.info(f&quot;  [LOG] {line}&quot;)&#10;                        last_log_line = len(lines)&#10;&#10;                # Check for success&#10;                if success_marker in logs:&#10;                    logger.info(f&quot;[OK] Processing completed successfully!&quot;)&#10;&#10;                    # Extract result URL&#10;                    urls = re.findall(url_pattern, logs)&#10;                    for url in reversed(urls):  # Get last URL&#10;                        if 'noxfvr-videos' in url and ('output/' in url or 'both/' in url or 'upscales/' in url or 'interps/' in url):&#10;                            logger.info(f&quot;[RESULT] Download URL: {url}&quot;)&#10;                            return url&#10;&#10;                    logger.warning(&quot;[WARN] Success marker found but no result URL&quot;)&#10;                    return None&#10;&#10;                # Check for pipeline failure (immediate termination)&#10;                pipeline_failed_marker = &quot;ERROR: Pipeline failed with exit code&quot;&#10;                if pipeline_failed_marker in logs:&#10;                    logger.error(f&quot;[ERROR] Pipeline failed - stopping monitoring&quot;)&#10;                    # Extract last error&#10;                    error_lines = [l for l in lines if 'ERROR' in l]&#10;                    if error_lines:&#10;                        logger.error(f&quot;[ERROR] Last error: {error_lines[-1][:200]}&quot;)&#10;                    return None  # Exit monitoring, instance will be destroyed&#10;&#10;                # Check for other errors (only report periodically)&#10;                if check_count == 1 or (check_count % 12 == 0):  # Check every 2 minutes&#10;                    if 'ERROR' in logs or 'FAILED' in logs:&#10;                        error_lines = [l for l in lines if 'ERROR' in l or 'FAILED' in l]&#10;                        if error_lines:&#10;                            logger.warning(f&quot;[WARN] Recent errors: {error_lines[-1][:100]}&quot;)&#10;&#10;                time.sleep(10)&#10;&#10;            except Exception as e:&#10;                consecutive_failures += 1&#10;                if consecutive_failures &lt;= 3:  # Only log first 3 failures&#10;                    logger.warning(f&quot;[WARN] Log fetch failed (attempt {consecutive_failures}): {e}&quot;)&#10;                time.sleep(10)&#10;&#10;        logger.error(f&quot;[ERROR] Monitoring timeout after {timeout}s&quot;)&#10;        return None&#10;&#10;    def _filter_existing_outputs(self, files: List) -&gt; List:&#10;        &quot;&quot;&quot;Filter out files that already have output.&quot;&quot;&quot;&#10;        if not self.b2_client:&#10;            return files&#10;&#10;        try:&#10;            # List existing outputs&#10;            output_objects = self.b2_client.list_objects(prefix='output/')&#10;            existing_stems = {obj.stem for obj in output_objects}&#10;&#10;            # Filter&#10;            filtered = []&#10;            skipped = 0&#10;&#10;            for file_obj in files:&#10;                stem = file_obj.stem&#10;                if stem in existing_stems:&#10;                    logger.info(f&quot;[WARN] Skipping {file_obj.key} - output exists&quot;)&#10;                    skipped += 1&#10;                else:&#10;                    filtered.append(file_obj)&#10;&#10;            if skipped &gt; 0:&#10;                logger.info(f&quot;Skipped {skipped} files with existing outputs&quot;)&#10;&#10;            return filtered&#10;&#10;        except Exception as e:&#10;            logger.warning(f&quot;Could not check existing outputs: {e}&quot;)&#10;            return files&#10;&#10;    def process_single_file(&#10;        self,&#10;        input_url: str,&#10;        output_name: Optional[str] = None,&#10;        preset: str = 'balanced'&#10;    ) -&gt; Dict[str, Any]:&#10;        &quot;&quot;&quot;&#10;        Process single file on Vast.ai.&#10;&#10;        Args:&#10;            input_url: Input file URL&#10;            output_name: Output file name (auto-generated if None)&#10;            preset: Preset name from config&#10;&#10;        Returns:&#10;            Processing result dict&#10;        &quot;&quot;&quot;&#10;        if not self.vast_client:&#10;            raise RuntimeError(&quot;Vast.ai client not initialized&quot;)&#10;&#10;        # Generate output name if not provided&#10;        if not output_name:&#10;            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')&#10;            output_name = f&quot;output_{timestamp}.mp4&quot;&#10;&#10;        logger.info(f&quot;[RUN] Processing file: {input_url}&quot;)&#10;        logger.info(f&quot;   Output: {output_name}&quot;)&#10;        logger.info(f&quot;   Preset: {preset}&quot;)&#10;&#10;        # Get preset config&#10;        preset_config = self.config.get('presets', {}).get(preset, {})&#10;        if not preset_config:&#10;            raise ValueError(f&quot;Preset not found: {preset}&quot;)&#10;&#10;        # Search for offers&#10;        offers = self.vast_client.search_offers(&#10;            min_vram_gb=preset_config.get('min_vram', 12),&#10;            max_price=preset_config.get('max_price', 0.5),&#10;            min_reliability=preset_config.get('min_reliability', 0.9),&#10;            limit=10,&#10;            host_whitelist=preset_config.get('host_whitelist'),&#10;            host_blacklist=preset_config.get('host_blacklist')&#10;        )&#10;&#10;        if not offers:&#10;            raise RuntimeError(&quot;No suitable offers found&quot;)&#10;&#10;        # Use best offer (first one - already sorted by price)&#10;        offer = offers[0]&#10;        logger.info(f&quot;[OK] Selected offer: {offer}&quot;)&#10;&#10;        # Build instance config&#10;        video_config = self.config.get('video', {})&#10;&#10;        # Get git repo URL and branch from config&#10;        git_repo = self.config.get('git_repo', 'https://github.com/zerotouchprod/vastai_inerup.git')&#10;        git_branch = self.config.get('git_branch', 'oop2')&#10;&#10;        # Build shell command (legacy format) - will be passed as args_str&#10;        # Format: git clone fresh, then run remote_runner.sh&#10;        git_clone_cmd = f'cd / &amp;&amp; rm -rf /workspace/project &amp;&amp; git clone -b {git_branch} {git_repo} /workspace/project'&#10;        runner_cmd = 'bash /workspace/project/scripts/remote_runner.sh'&#10;        full_cmd = f'{git_clone_cmd} &amp;&amp; {runner_cmd}'&#10;        &#10;        # Wrap in bash -c&#10;        shell_cmd = f&quot;bash -c '{full_cmd}'&quot;&#10;&#10;        instance_config = VastInstanceConfig(&#10;            image=self.config.get('image', ''),&#10;            disk=50,&#10;            env={&#10;                'INPUT_URL': input_url,&#10;                'B2_OUTPUT_KEY': f&quot;output/{output_name}&quot;,&#10;                'B2_BUCKET': os.getenv('B2_BUCKET', ''),&#10;                'B2_KEY': os.getenv('B2_KEY', ''),&#10;                'B2_SECRET': os.getenv('B2_SECRET', ''),&#10;                'B2_ENDPOINT': os.getenv('B2_ENDPOINT', 'https://s3.us-west-004.backblazeb2.com'),&#10;                'MODE': video_config.get('mode', 'both'),&#10;                'SCALE': str(video_config.get('scale', 2)),&#10;                'TARGET_FPS': str(video_config.get('target_fps', 60)),&#10;                'USE_NATIVE_PROCESSORS': '1',  # Use new Python code!&#10;            },&#10;            args_str=shell_cmd,  # Shell command for container to execute&#10;            # No onstart, no label - reuse cached image on same host&#10;        )&#10;&#10;        # Create instance&#10;        instance = self.vast_client.create_instance(offer.id, instance_config)&#10;        logger.info(f&quot;[OK] Created instance: {instance}&quot;)&#10;&#10;        # Wait for running&#10;        try:&#10;            instance = self.vast_client.wait_for_running(&#10;                instance.id,&#10;                timeout=300,&#10;                poll_interval=10&#10;            )&#10;            logger.info(f&quot;[OK] Instance running: {instance}&quot;)&#10;        except TimeoutError as e:&#10;            logger.error(f&quot;Instance failed to start: {e}&quot;)&#10;            raise&#10;&#10;        # Monitor processing&#10;        logger.info(f&quot;[MONITOR] Monitoring instance #{instance.id} for completion...&quot;)&#10;        result_url = self._monitor_processing(instance.id, timeout=7200)  # 2 hours max&#10;&#10;        # Stop instance (keep for debugging instead of destroying)&#10;        logger.info(f&quot;[CLEANUP] Stopping instance #{instance.id}...&quot;)&#10;        self.vast_client.stop_instance(instance.id)&#10;        logger.info(f&quot;[OK] Instance stopped (kept for debugging)&quot;)&#10;&#10;        return {&#10;            'instance_id': instance.id,&#10;            'input_url': input_url,&#10;            'output_name': output_name,&#10;            'result_url': result_url,&#10;            'status': 'completed' if result_url else 'failed'&#10;        }&#10;&#10;    def process_batch(&#10;        self,&#10;        input_dir: str,&#10;        preset: str = 'balanced',&#10;        dry_run: bool = False&#10;    ) -&gt; List[Dict[str, Any]]:&#10;        &quot;&quot;&quot;&#10;        Process batch of files from B2 directory.&#10;&#10;        Args:&#10;            input_dir: Input directory in B2&#10;            preset: Preset name from config&#10;            dry_run: If True, only show what would be processed&#10;&#10;        Returns:&#10;            List of processing results&#10;        &quot;&quot;&quot;&#10;        # List files&#10;        files = self.list_input_files(input_dir)&#10;&#10;        if not files:&#10;            logger.info(&quot;No files to process&quot;)&#10;            return []&#10;&#10;        logger.info(f&quot;[STAT] {len(files)} files to process&quot;)&#10;&#10;        if dry_run:&#10;            logger.info(&quot;[DRY] Dry run - not creating instances&quot;)&#10;            for idx, file_obj in enumerate(files, 1):&#10;                logger.info(f&quot;  {idx}. {file_obj.key} ({file_obj.size} bytes)&quot;)&#10;            return []&#10;&#10;        # Process each file&#10;        results = []&#10;&#10;        for idx, file_obj in enumerate(files, 1):&#10;            logger.info(f&quot;\n{'='*60}&quot;)&#10;            logger.info(f&quot;Processing file {idx}/{len(files)}&quot;)&#10;            logger.info(f&quot;{'='*60}\n&quot;)&#10;&#10;            try:&#10;                # Get presigned URL&#10;                input_url = self.b2_client.get_presigned_url(&#10;                    file_obj.key,&#10;                    expires_in=7200  # 2 hours&#10;                )&#10;&#10;                # Generate output name&#10;                timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')&#10;                output_name = f&quot;{file_obj.stem}_{timestamp}.mp4&quot;&#10;&#10;                # Process&#10;                result = self.process_single_file(&#10;                    input_url=input_url,&#10;                    output_name=output_name,&#10;                    preset=preset&#10;                )&#10;&#10;                results.append(result)&#10;                logger.info(f&quot;[OK] File {idx}/{len(files)} submitted&quot;)&#10;&#10;            except Exception as e:&#10;                logger.error(f&quot;[ERROR] Failed to process {file_obj.key}: {e}&quot;)&#10;                import traceback&#10;                traceback.print_exc()&#10;                continue&#10;&#10;        return results&#10;&#10;&#10;def main():&#10;    &quot;&quot;&quot;Main entry point.&quot;&quot;&quot;&#10;    parser = argparse.ArgumentParser(&#10;        description='Unified Batch Processor for Vast.ai - reads defaults from config.yaml'&#10;    )&#10;&#10;    parser.add_argument('--config', default='config.yaml',&#10;                       help='Config file (default: config.yaml)')&#10;    parser.add_argument('--input', help='Single input file URL (overrides config)')&#10;    parser.add_argument('--input-dir', help='Input directory in B2 (overrides config)')&#10;    parser.add_argument('--output', help='Output file name (for single file)')&#10;    parser.add_argument('--preset', help='Preset name (overrides config)')&#10;    parser.add_argument('--dry-run', action='store_true', default=None,&#10;                       help='Show what would be processed (overrides config)')&#10;    parser.add_argument('--skip-existing', action='store_true', default=None,&#10;                       help='Skip files with existing output (overrides config)')&#10;&#10;    args = parser.parse_args()&#10;&#10;    try:&#10;        # Initialize processor&#10;        processor = BatchProcessor(config_path=args.config)&#10;&#10;        # Get batch config from config.yaml&#10;        batch_config = processor.config.get('batch', {})&#10;        video_config = processor.config.get('video', {})&#10;&#10;        # Determine input source (CLI args override config)&#10;        input_url = args.input&#10;        # Priority: CLI &gt; video.input_dir (remote) &gt; batch.input_dir (local)&#10;        # Remote config should override local config&#10;        input_dir = args.input_dir or video_config.get('input_dir') or batch_config.get('input_dir')&#10;        preset = args.preset or batch_config.get('preset', 'balanced')&#10;        dry_run = args.dry_run if args.dry_run is not None else batch_config.get('dry_run', False)&#10;        skip_existing = args.skip_existing if args.skip_existing is not None else batch_config.get('skip_existing', True)&#10;&#10;        # Validate: need either input or input_dir&#10;        if not input_url and not input_dir:&#10;            logger.error(&quot;[ERROR] No input specified!&quot;)&#10;            logger.error(&quot;Either:&quot;)&#10;            logger.error(&quot;  1. Set 'batch.input_dir' in config.yaml&quot;)&#10;            logger.error(&quot;  2. Use --input &lt;url&gt; for single file&quot;)&#10;            logger.error(&quot;  3. Use --input-dir &lt;dir&gt; for batch&quot;)&#10;            sys.exit(1)&#10;&#10;        # Validate credentials before processing&#10;        if input_dir and not processor.b2_client:&#10;            logger.error(&quot;[ERROR] B2 client not initialized - cannot list files from B2&quot;)&#10;            logger.error(&quot;Please set environment variables:&quot;)&#10;            logger.error(&quot;  $env:B2_KEY='your_key_id'&quot;)&#10;            logger.error(&quot;  $env:B2_SECRET='your_application_key'&quot;)&#10;            logger.error(&quot;  $env:B2_BUCKET='noxfvr-videos'&quot;)&#10;            sys.exit(1)&#10;&#10;        if not processor.vast_client:&#10;            logger.error(&quot;[ERROR] Vast.ai client not initialized - cannot create instances&quot;)&#10;            logger.error(&quot;Please set environment variable:&quot;)&#10;            logger.error(&quot;  $env:VAST_API_KEY='your_vast_api_key'&quot;)&#10;            sys.exit(1)&#10;&#10;        # Process&#10;        if input_url:&#10;            # Single file&#10;            logger.info(f&quot;[FILE] Processing single file: {input_url}&quot;)&#10;            result = processor.process_single_file(&#10;                input_url=input_url,&#10;                output_name=args.output,&#10;                preset=preset&#10;            )&#10;            logger.info(f&quot;\n[OK] Processing submitted: {result}&quot;)&#10;&#10;        elif input_dir:&#10;            # Batch&#10;            logger.info(f&quot;[DIR] Processing batch from: {input_dir}&quot;)&#10;            logger.info(f&quot;[CFG] Preset: {preset}&quot;)&#10;            logger.info(f&quot;[DRY] Dry run: {dry_run}&quot;)&#10;            logger.info(f&quot;[SKIP] Skip existing: {skip_existing}\n&quot;)&#10;&#10;            results = processor.process_batch(&#10;                input_dir=input_dir,&#10;                preset=preset,&#10;                dry_run=dry_run&#10;            )&#10;            logger.info(f&quot;\n[OK] Batch processing complete: {len(results)} files submitted&quot;)&#10;&#10;    except Exception as e:&#10;        logger.error(f&quot;\n[ERROR] Error: {e}&quot;)&#10;        import traceback&#10;        traceback.print_exc()&#10;        sys.exit(1)&#10;&#10;&#10;if __name__ == '__main__':&#10;    main()&#10;&#10;" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>